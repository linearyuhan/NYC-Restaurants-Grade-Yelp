cor(fit1$residuals, fit2$residuals)
cor(fit1$residuals, fit2$residuals)^2
dfCombined=data.frame(rbind(cbind(Group=1, Speech=dfData$Speech, Span=dfData$Span), cbind(Group=2, Speech=fit1$residuals, Span=dfData$Span), cbind(Group=3, Speech=fit1$residuals, Span=fit2$residuals)))
Span=dfData$Span )
,cbind( Group=2, Speech=fit1$residuals, Span=dfData$Span )
,cbind( Group=3, Speech=fit1$residuals, Span=fit2$residuals )
) )
dfCombined <- data.frame( rbind( cbind( Group=1, Speech=dfData$Speech, Span=dfData$Span )
,cbind( Group=2, Speech=fit1$residuals, Span=dfData$Span )
,cbind( Group=3, Speech=fit1$residuals, Span=fit2$residuals )
) )
dfCombined <- data.frame( rbind( cbind( Group=1, Speech=dfData$Speech, Span=dfData$Span )
,cbind( Group=2, Speech=fit1$residuals, Span=dfData$Span )
,cbind( Group=3, Speech=fit1$residuals, Span=fit2$residuals )
))
dfCombined <- data.frame( rbind( cbind( Group=1, Speech=dfData$Speech, Span=dfData$Span ) , cbind(Group=2, Speech=fit1$residuals, Span=dfData$Span), cbind(Group=3, Speech=fit1$residuals, Span=fit2$residuals) ))
dfCombined <- data.frame( rbind( cbind( Group=1, Speech=dfData$Speech, Span=dfData$Span )
,cbind( Group=2, Speech=fit1$residuals, Span=dfData$Span )
,cbind( Group=3, Speech=fit1$residuals, Span=fit2$residuals )
) )
dfData <- data.frame(
Age     = c( 14, 23, 30, 50, 39, 67 )
,Speech = c(  1,  2,  2,  4,  3,  6 )
,Span   = c(  4,  4,  7,  7, 10, 10 )
)
dfData
fit1 <- lm( Speech ~ Age, data=dfData )
fit2 <- lm( Span ~ Age, data=dfData )
fit1
fit2
dfCombined <- data.frame( rbind( cbind( Group=1, Speech=dfData$Speech, Span=dfData$Span )
,cbind( Group=2, Speech=fit1$residuals, Span=dfData$Span )
,cbind( Group=3, Speech=fit1$residuals, Span=fit2$residuals )
) )
dfCombined$Group <- factor( dfCombined$Group, labels=c( 'Zero Order Correlation', 'Semi-Partial Correlation', 'Partial Correlation' ) )
ggplot( dfCombined, aes( x=Speech, y=Span, z=Group ) ) + geom_point() +
geom_smooth( method='lm', se=FALSE, fullrange=TRUE ) + ylab( 'Memory Span' ) +
facet_wrap( ~ Group )
dfCombined$Group
dfZ=data.frame(Age=dfData$Age, Speech. Prime=fit1$residuals)
dfZ <- data.frame( Age=dfData$Age, Speech.Prime=fit1$residuals )
dfZ
dfZ=data.frame(Age=dfData$Age, Speech.Prime=fit1$residuals)
dfZ
cor(dfZ)
with( dfData, spcor.test( Span, Speech, Age ) )
summary( Fit1 <- lm( Span ~ Age, data=dfData ) )
summary( Fit2 <- lm( Span ~ Age + Speech, data=dfData ) )
with( dfData, spcor.test( Span, Age, Speech ) )
spcor.test( Span, Age, Speech )
spcor.test( Span, Age, Speech, data=dfData )
library(   ppcor )
library(  GGally )
library( ggplot2 )
library("ppcor")
dfData <- data.frame(
Age     = c( 14, 23, 30, 50, 39, 67 )
,Speech = c(  1,  2,  2,  4,  3,  6 )
,Span   = c(  4,  4,  7,  7, 10, 10 )
)
dfData
cor( dfData )
rm(list=ls())
library(ppcor)
library("ppcor")
dfData <- data.frame(
Age=c(  4,  4,  7,  7, 10, 10 )   # X_1
,Speech=c( 14, 23, 30, 50, 39, 67 )   # X_2
,Memory=c(  1,  2,  2,  4,  3,  6 ) )
dfData
r12=cor(dfData$Memory, dfData$Age)
r12
r12^2
cor(dfData)
ry1=cor(dfData$Memory, dfData$Age)
ry2=cor(dfData$Memory, dfData$Speech)
ry12=cor(dfData$age, dfData$Speech)
ry2=cor(dfData$Memory, dfData$Speech)
ry12=cor(dfData$age, dfData$Speech)
ry12=cor(dfData$Age, dfData$Speech)
ry1
ry2
ry12
ry3=(dfData$Memory, dfData$Speech)
ry3=cor(dfData$Memory, dfData$Speech)
ry4=cor(dfData$Age, dfData$Speech)
ry2
ry3
ry4
ry4=cor(dfData$Speech, dfData$Age)
ry4
ry4=cor(dfData$Age, dfData$Speech)
ry4
ry5=cor(dfData$Memory, dfData$Speech, dfData$Age)
( pry1.2 <- ( ry1 - ( ry2 * r12 ) ) / ( sqrt( 1 - ry2^2 ) * sqrt( 1 - r12^2 )  ) )
( pry2.1 <- ( ry2 - ( ry1 * r12 ) ) / ( sqrt( 1 - ry1^2 ) * sqrt( 1 - r12^2 )  ) )
fit=lm(Memory~Age+Speech, data=dfData)
fit
summary(fit)
tryit=lm(Memory~Age, data=dfData)
summary(tryit)
summary(fit)
summary(fit.memory.age=lm(Memory~Age, data=dfData))
summary(fit.memory.age=lm(dfData$Memory~dfData$Age))
fit.memory.age=lm(dfData$Memory~dfData$Age)
summary(fit.memory.age)
summary( Fit.Memory.Speech <- lm( Memory ~ Speech, data=dfData ) )
summary( Fit.Age.Speech    <- lm( Age ~ Speech, data=dfData ) )
summary( Fit.Speech.Age    <- lm( Speech ~ Age, data=dfData ) )
cor( dfData$Speech, Fit.Age.Speech$fitted )
cor( dfData$Speech, Fit.Age.Speech$residuals )
cor( Fit.Memory.Speech$residuals, Fit.Age.Speech$residuals )
cor( Fit.Memory.Age$residuals, Fit.Speech.Age$residuals )
library(ppcor)
pcor(dfData)
with( dfData, spcor.test( Span, Age, Speech ) )
with( dfData, spcor.test( Memory, Age, Speech ) )
with( dfData, spcor.test( Memory, Speech, Age ) )
with( dfData, spcor.test( Speech,Age, Memory ) )
dfData <- data.frame(
Age=c(  4,  4,  7,  7, 10, 10 )   # X_1
,Speech=c( 14, 23, 30, 50, 39, 67 )   # X_2
,Memory=c(  1,  2,  2,  4,  3,  6 ) )
dfData
library("ppcor")
download.packages("MASS")
library(ppcor)
cor(dfData$Age, dfData$Memory)
cor(dfData$Age, dfData$Speech)
cor(dfData$Memory, dfData$Speech)
cor(dfData$Memory, dfData$Speech)^2
with(dfData, spor.test(dfData$Memory, dfData$Age, dfData$Speech))
library(ppcor)
with(dfData, spor.test(Memory, Age, Speech))
read(ppcor)
dfData <- data.frame(
+        Age=c(  4,  4,  7,  7, 10, 10 )   # X_1
+    ,Speech=c( 14, 23, 30, 50, 39, 67 )   # X_2
+    ,Memory=c(  1,  2,  2,  4,  3,  6 )
spcor(dfData)
with(dfData, spor.test(Memory, Age, Speech))
with(dfData, spor.test(dfData$Memory, dfData$Age, dfData$Speech))
library(ppcor)
with(dfData, spcor.test(Memory, Speed, Age))
with(dfData, spcor.test(Memory, Speech, Age))
r=with(dfData, spcor.test(Memory, Speech, Age))
r[estimate]
r$estimate
r$estimate^2
swirl
140/145
145/150
rm(list=ls())
install.packages('dplyr')
require(dplyr)
library(delyr)
library(dplyr)
data(mtcars)
names(mtcars)
View(mtcars)
mtcars=add_rownames(mtcars, 'cartype')
View(mtcars)
?add_rowname
?add_rownames
View(mtcars)
View(mtcars)
mtcars=mutate(mtcars, newroll=if_else(mtcars$mpg >= 20, 'high', 'low'))
View(mtcars)
distinct(mtcars, mtcars$hp)
mycars=arrange(mtcars, mtcars$hp)
View(mycars)
mycars=arrange(mtcars, desc(mtcars$hp))
View(mtcars)
View(mycars)
rm(list=ls())
install.packages('twitterR')
library(twitterR)
install.packages('twitterR')
install.packages('twitteR')
library(twitteR)
consumer_key='YKHqhc7VJQ7E9uQC79RG6AJmn'
consumer_secret='1cwXZJxkt20hTxRbDAPSNjq2YcquuF5tQGSxl5pbdCU4j5QX3a'
access_token='112772224-YVjJzsH8937wP8mP1D2EJmnd4mIIyS7QTMMIksfN'
access_secret='Zl34D5TbtC5zpdX7hCuDe2EjSQEHUms0HCijucTJRfCmM'
?corpus
?Corpus
??Corpus
install.packages('Rcurl')
install.packages('RCurl')
require(RCurl)
require(bitops)
?Corpus
install.packages('tm')
require(tm)
library(tm)
library(NLP)
?Corpus
data(tidy)
text <- c("Because I could not stop for Death -",
"He kindly stopped for me -",
"The Carriage held but just Ourselves -",
"and Immortality")
text
library(dplyr)
text_df=data.frame(line=1:4, text=text)
text_df
library(tidytext)
install.packages('tidytext')
library(tidytext)
?unnest_tokens
text_df2=unnest_tokens(text, word)
text_df2=unnest_tokens(word, text)
text_df2 %>% unnest_tokens(word, text)
text_df %>% unnest_tokens(word, text)
text_df %>%
unnest_tokens(word, text)
text_df %>%unnest_tokens(word, text)
text_df = unnest_tokens(word, text_df$text)
text_df %>% unnest_tokens(word, text_df$text)
text_df %>% unnest_tokens(word, txt)
text_df %>% unnest_tokens(word, text)
text_df
text_df %>% unnest_tokens(word, text_df$text)
attach(text_df)
text_df
text_df %>% unnest_tokens(word, text)
text_df %>% unnest_tokens(text_df, word, text)
text_df
text_df %>% unnest_tokens(text_df, word, txt)
text_df %>% unnest_tokens(text_df, word, text)
text_df %>% unnest_tokens_(text_df, word, text)
text_df %>% unnest_tokens_(word, text)
text %>% unnest_tokens(word, text)
text_df %>% unnest_tokens(word, text)
txt <- c("Because I could not stop for Death -",
"He kindly stopped for me -",
"The Carriage held but just Ourselves -",
"and Immortality")
text_df=data.frame(line=1:4, text=txt)
text_df
library(tidytext)
text_df %>% unnest_tokens(word, text)
text_df=data.frame(line=1:4, txt=txt)
text_df
text_df %>% unnest_tokens(word, txt)
text_df=data.frame(txt=txt)
text_df
text_df %>% unnest_tokens(word, txt)
text_df=text_df %>% unnest_tokens(word, txt)
attach(text_df)
text_df <- text_df %>% unnest_tokens(word, txt)
text_df <- text_df %>% unnest_tokens(token='words', txt)
text_df <- text_df %>% unnest_tokens(token='word', txt)
text_df <- text_df %>% unnest_tokens(word, txt)
text_df <- text_df %>% unnest_tokens_(word, txt)
str(txt)
names(txt)
stringasfactor(txt)
stringAsFactors(txt)
text_df=data.frame(txt=txt)
names(text_df)
text_df$txt=as.factor(text_df$txt)
text_df <- text_df %>% unnest_tokens_(word, txt)
library(tidytext)
text_df <- text_df %>% unnest_tokens_(word, txt)
text_df <- text_df %>% unnest_tokens_(words, txt)
text_df <- text_df %>% unnest_tokens(word, txt)
rm(list=ls())
text <- c("Because I could not stop for Death -",
"He kindly stopped for me -",
"The Carriage held but just Ourselves -",
"and Immortality")
text
library(dplyr)
text_df <- data_frame(line = 1:4, text = text)
library(tidytext)
text_df %>%
unnest_tokens(word, text)
library(tidytext)
text <- c("Because I could not stop for Death -",
"He kindly stopped for me -",
"The Carriage held but just Ourselves -",
"and Immortality")
text
library(dplyr)
text_df <- data_frame(line = 1:4, text = text)
library(tidytext)
text_df = unnest_tokens(word, text)
text_df &>& unnest_tokens(word, text)
text_df %>% unnest_tokens(word, text)
library(janeaustenr)
library(dplyr)
library(stringr)
data(janeaustenr)
original_book=austen_books()
View(original_book)
View(original_book)
ungroup(original_book)
je=ungroup(original_book)
View(je)
View(original_book)
?ungroup
?mutate
View(original_book)
tidy_book=original_book %>% unnest_tokens(word, text)
library(tidytext)
tidy_book=original_book %>% unnest_tokens(word, text)
View(tidy_book)
data("stop_words")
view(stop_words)
str(stopwords)
tidybook=tidy_book %>% anti_join(stop_words)
tidybook
View(tidy_book)
persuasion=filter(str_detect(tidy_book$book, 'Persuasion'))
library(dplyr)
persuasion=filter(str_detect(tidy_book$book, 'Persuasion'))
library(stringr)
persuasion=filter(str_detect(tidy_book$book, 'Persuasion'))
persuasion=filter(tidy_book$book, 'Persuasion')
?subset
persuasion=subset(tidy_book$book == 'Persuasion')
persuasion=subset(tidy_book, tidy_book$book == 'Persuasion')
persuasion
tidybook
count(tidybook$word, sort=T)
count(tidybook$word, sort=TRUE)
tidybook %>% count(word, sort=TRUE)
countword=tidybook %>% count(word, sort=TRUE)
library(ggplot2)
g=ggplot(countword, aes(countword$word, countword$n))
g
g=ggplot(countword, aes(countword$word, countword$n))+
geom_bar(countword$word)
g=ggplot(countword, aes(countword$word))+
geom_bar(countword$word)
g=ggplot(countword, aes(countword$word))+
geom_bar()
g
g=ggplot(countword, aes(countword$word))+
geom_histogram(binwidth = 20)
g
qplot(countword$word, geom='histogram')
?geom
qplot(countword$word, geom='bar')
countword
library(scale)
library(scales)
?scale_y_continuous
min(countword$n)
g=ggplot(countword, aes(countword))+goem_bar()+scale_y_continuous(limits=c(1, 1900))
g=ggplot(countword, aes(countword))+geom_bar()+scale_y_continuous(limits=c(1, 1900))
g
g = ggplot(countword, aes(countword))
+ geom_bar()
+ scale_y_continuous(limits = c(0, 1900))
g = ggplot(countword, aes(countword)) + geom_bar() + scale_y_continuous(limits = c(0, 1900))
g
g = ggplot(countword, aes(countword$word)) + geom_bar() + scale_y_continuous(limits = c(0, 1900))
g
attach(tidybook)
tidybook %>% count(word, sort=TRUE) %>% filter(n>700) %>% ggplot(aes(word, n)) +
geom_col() + xlab('word')
tidybook %>% count(word, sort=TRUE) %>% filter(n>700)%>%
mutate(word, reorder(word,n)) %>% ggplot(aes(word, n)) +
geom_col() + xlab('word')
tidybook %>% count(word, sort=TRUE) %>% filter(n>700)%>%
mutate(word, reorder(word,n)) %>% ggplot(aes(word, n)) +
geom_col() + xlab('word') + coord_flip()
tidybook %>% count(word, sort=TRUE) %>% filter( n > 700 )%>%
mutate(word=reorder(word,n)) %>% ggplot(aes(word, n)) +
geom_col() + xlab('word') + coord_flip()
tidybook %>% count(word, sort=TRUE) %>% filter( n > 700 )%>%
ggplot(aes(word, n)) +
geom_col() + xlab('word')
tidybook %>% count(word, sort=TRUE) %>% filter( n > 700 )%>%
mutate(word=reorder(word,n)) %>% ggplot(aes(word, n)) +
geom_col() + xlab('word') +  coord_flip()
hgwells <- gutenberg_download(c(35, 36, 5230, 159))
library(gutenbergr)
text_df %>% unnest_tokens(word, text) %>% anti_join(stop_words)
text=text_df %>% unnest_tokens(word, text) %>% anti_join(stop_words)
text
text_df
knitr::opts_chunk$set(fig.height=5, fig.width=11, warning = F)
library(dplyr)
library(ggplot2)
library(Rcpp)
library(Amelia)
# constants for homework assignments
hw_num <- 1
hw_due_date <- "September 17, 2017"
radio <- read.csv("Survey.csv", header=T, na.strings = c(""))
16.17-2×2.036
16.17 - 2*2.036
predict(model_5, newcar,  interval = "predict", se.fit = TRUE)
model_5 = lm(mpg ~ cylinders + displacement + horsepower + weight + cylinders*horsepower, data = auto_data)
knitr::opts_chunk$set(fig.height=5, fig.width=11, warning = F)
library(dplyr)
library(ggplot2)
library(Rcpp)
library(Amelia)
radio2= radio %>% select(c(28,30,29,31,32,33,24))
radio2_r = radio[, c(28,30,29,31,32,33,24)]
colnames(radio2)=c("age", "gender", "education", "income", "sirius", "wharton", "worktime")
names(radio2)
sum(is.na(radio2))
which(is.na(radio2$wharton))
radio3 = radio2[-c(479, 764, 856, 1481), ]
which(is.na(radio3$sirius))
radio3 = radio3[-c(261, 558, 577), ]
radio4 = na.omit(radio3)
which(radio4$age > 100)
which(radio4$age > 100)
str(radio4$age)
radio4$age_num = as.numeric(radio4$age)
which(radio4$age > 100)
which(radio4$age > 100)
library(dplyr)
which(is.na(radio2$wharton))
which(radio4$age > 100)
summary(radio4$age)
str(radio4$age)
radio4$age = as.numeric(as.character(f))
radio4$age = as.numeric(as.character(radio4$age))
radio4 = na.omit(radio3)
radio4$age = as.numeric(as.character(radio4$age))
which(is.na(radio4$gender))
str(radio4$age)
knitr::opts_chunk$set(echo = TRUE, results = "hide")
if(!require('pacman')) {
install.packages('pacman')
}
pacman::p_load(ISLR, leaps, car, tidyverse, GGally, reshape2)
fit.exh <- regsubsets(LogSalary ~., data2, nvmax=25, method="exhaustive")
data2 <- read.csv(file = "Hitters_comp", row.names = "X")
fit.all <- lm(LogSalary ~., data = data2)
fit.exh <- regsubsets(LogSalary ~., data2, nvmax=25, method="exhaustive")
names(fit.exh)
summary(fit.exh)
f.e <- summary(fit.exh)
f.e
names(f.e)
f.e$which  #we are looking at the one that says true. intercept always says true
data.frame(variables=(1:length(f.e$rsq)), r_squared=f.e$rsq)
data.frame(variables = (1:length(f.e$rsq)),
r_squared = f.e$rsq,
rss = f.e$rss,
bic = f.e$bic,
cp = f.e$cp)
data.frame(cp = f.e$cp)
data.frame(variables=(1:length(f.e$cp)), cp = f.e$cp)
0.583-0.346
rm(list = ls())
library(DAAG)
library(lattice)
library(DAAG)
?DAAG
data("socsupport")
head(socsupport)
View(socsupport)
attach(socsupport)
names(socsupport)
x = as.matrix(data.frame(emotional, affect, psi))
x
out1 = lm(BDI ~ emotional + affect + psi, data = socsupport)
summary(out1)
out2 = glm(x, BDI, family = "gaussian", alpha = 0)
out2 = glmnet(x, BDI, family = "gaussian", alpha = 0)
library(glmnet)
library(glmnet)
out2 = glmnet(x, BDI, family = "gaussian", alpha = 0)
?glmnet
out2
plot(log(out2$lambda), out2$beta[2], ylim = c(-2,2), type = 'l', col = 'blue', lws = 3,
xlab = 'log of lambda', ylab = 'regression coefficient')
plot(log(out2$lambda), out2$beta[2], ylim = c(-2,.2), type = 'l', col = 'blue', lws = 3,
xlab = 'log of lambda', ylab = 'regression coefficient')
plot(log(out2$lambda), out2$beta[2,], ylim = c(-2,.2), type = 'l', col = 'blue', lws = 3,
xlab = 'log of lambda', ylab = 'regression coefficient')
lines(log(out2$lambda), out2$beta[1,], type = 'l', col = 'red', lwd = 3)
rm(list = ls())
rm(list = ls())
library(dplyr)
library(lubridate)
library(sqldf)
rm(list = ls())
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
library(lubridate)
install.packages('sqldf')
library(sqldf)
install.packages('RSQLite')
install.packages("RSQLite")
library(RSQLite)
install.packages('doBy')
library(doBy)
install.packages('ggplot2')
library(ggplot2)
esdata = read.csv('performance_challenge_espark_data.csv', header = T)
math = read.csv('performance_challenge_math_data.csv', header = T)
reading = read.csv('performance_challenge_reading_data.csv', header = T)
setwd("~/Desktop/Job Application/Tech Companies/Glossier/assignment_files")
borough_names = read.table(file = 'borough_names.tsv', sep = '\t', header = TRUE)
cuisine_names = read.table(file = 'cuisine_names.tsv', sep = '\t', header = TRUE)
res_attributes = read.table(file = 'restaurant_attributes.tsv', sep = '\t', header = TRUE, fill = TRUE)
res_names = read.table(file = 'restaurant_names.tsv', sep = '\t', header = TRUE)
res_violations = read.table(file = 'restaurant_violations.tsv', sep = '\t', header = TRUE)
violation_names = read.table(file = 'violation_names.tsv', sep = '\t', header = TRUE)
View(res_violations)
summary(res_violations)
